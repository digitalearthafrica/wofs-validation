{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Assessment of Water Observations from Space (WOfS) Product in Africa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Now that we have run WOfS classification for each AEZs in Africa, its time to conduct an accuracy assessment. The data used for assessing the accuracy was collected previously and set aside. It is stored in the Results folder: `Results/WOfS_Assessment/Point_Based/Intermediate_Per_AEZ`.\n",
    "\n",
    "Accuracy assessment for WOfS product in Africa includes generating a confusion error matrix for a WOFL binary classification.\n",
    "The inputs for the estimating the accuracy of WOfS derived product are a binary classification WOFL layer showing water/non-water and a shapefile containing validation points collected by [Collect Earth Online](https://collect.earth/) tool. Validation points are the ground truth or actual data while the extracted value for each location from WOFL is the predicted value. \n",
    "\n",
    "This notebook will explain how you can perform accuracy assessment for WOfS using collected ground truth dataset. It will output a confusion error matrix containing overall, producer's and user's accuracy, along with the F1 score for each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import rasterio\n",
    "import xarray\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy, scipy.ndimage\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #this will suppress the warnings for multiple UTM zones in your AOI \n",
    "\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score  \n",
    "from deafrica_tools.plotting import map_shapefile,display_map, rgb\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.datahandling import wofs_fuser, mostcommon_crs,load_ard,deepcopy\n",
    "from deafrica_tools.dask import create_local_dask_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets\n",
    "Ground truth points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../02_Validation_results/WOfS_Assessment/wofs_ls/Sahel_wofs_ls_valid.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Northern_wofs_ls_valid.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Eastern_wofs_ls_valid.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Central_wofs_ls_valid.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Indian_ocean_wofs_ls_valid.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Western_wofs_ls_valid.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Southern_wofs_ls_valid.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the ground truth data \n",
    "#For each AEZ\n",
    "file_path = ('../02_Validation_results/WOfS_Assessment/wofs_ls/')\n",
    "validation_files = [i for i in glob.glob(os.path.join(file_path, '*.{}'.format('csv')))]\n",
    "validation_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "n samples for Sahel : 1224\n",
      "         NoWater   Water   Total  Producer's\n",
      "ACTUAL                                      \n",
      "NoWater   390.00  120.00   510.0       76.47\n",
      "Water      80.00  634.00   714.0       88.80\n",
      "Total     470.00  754.00  1224.0         NaN\n",
      "User's     82.98   84.08     NaN       83.66\n",
      "F-score     0.80    0.86     NaN         NaN\n",
      "\n",
      "\n",
      "n samples for Northern : 1125\n",
      "         NoWater   Water   Total  Producer's\n",
      "ACTUAL                                      \n",
      "NoWater   393.00   71.00   464.0       84.70\n",
      "Water     113.00  548.00   661.0       82.90\n",
      "Total     506.00  619.00  1125.0         NaN\n",
      "User's     77.67   88.53     NaN       83.64\n",
      "F-score     0.81    0.86     NaN         NaN\n",
      "\n",
      "\n",
      "n samples for Eastern : 2669\n",
      "         NoWater    Water   Total  Producer's\n",
      "ACTUAL                                       \n",
      "NoWater   651.00    63.00   714.0       91.18\n",
      "Water     277.00  1678.00  1955.0       85.83\n",
      "Total     928.00  1741.00  2669.0         NaN\n",
      "User's     70.15    96.38     NaN       87.26\n",
      "F-score     0.79     0.91     NaN         NaN\n",
      "\n",
      "\n",
      "n samples for Central : 405\n",
      "         NoWater   Water  Total  Producer's\n",
      "ACTUAL                                     \n",
      "NoWater    44.00   15.00   59.0       74.58\n",
      "Water      56.00  290.00  346.0       83.82\n",
      "Total     100.00  305.00  405.0         NaN\n",
      "User's     44.00   95.08    NaN       82.47\n",
      "F-score     0.55    0.89    NaN         NaN\n",
      "\n",
      "\n",
      "n samples for Indian_ocean : 2283\n",
      "         NoWater    Water   Total  Producer's\n",
      "ACTUAL                                       \n",
      "NoWater   376.00    49.00   425.0       88.47\n",
      "Water     491.00  1367.00  1858.0       73.57\n",
      "Total     867.00  1416.00  2283.0         NaN\n",
      "User's     43.37    96.54     NaN       76.35\n",
      "F-score     0.58     0.84     NaN         NaN\n",
      "\n",
      "\n",
      "n samples for Western : 1055\n",
      "         NoWater   Water   Total  Producer's\n",
      "ACTUAL                                      \n",
      "NoWater   160.00   19.00   179.0       89.39\n",
      "Water     197.00  679.00   876.0       77.51\n",
      "Total     357.00  698.00  1055.0         NaN\n",
      "User's     44.82   97.28     NaN       79.53\n",
      "F-score     0.60    0.86     NaN         NaN\n",
      "\n",
      "\n",
      "n samples for Southern : 1562\n",
      "         NoWater   Water   Total  Producer's\n",
      "ACTUAL                                      \n",
      "NoWater   571.00   35.00   606.0       94.22\n",
      "Water     171.00  785.00   956.0       82.11\n",
      "Total     742.00  820.00  1562.0         NaN\n",
      "User's     76.95   95.73     NaN       86.81\n",
      "F-score     0.85    0.88     NaN         NaN\n"
     ]
    }
   ],
   "source": [
    "t=[]\n",
    "for v in validation_files:\n",
    "    df = pd.read_csv(v, delimiter=\",\").rename(columns={\"WATERFLAG\": \"ACTUAL\"})\n",
    "    aez = v[49:-18]\n",
    "    # setting the class_wet column to be prediction\n",
    "    df[\"PREDICTION\"] = df[\"CLASS_WET\"].apply(lambda x: \"1\" if x >= 1 else \"0\")\n",
    "\n",
    "    # Remove the duplicated plot IDs which means those that are labeled for similar month as 0, 1, 2  or 3.\n",
    "    df = df.drop_duplicates([\"LAT\", \"LON\", \"MONTH\"], keep=False)\n",
    "\n",
    "    # Filter out those rows that are labeled more than 1 or there is no clear WOfS/SCL observations\n",
    "    indexNames = df[\n",
    "        (df[\"ACTUAL\"] > 1) | (df[\"CLEAR_OBS\"] == 0.0) | (df[\"CLEAR_OBS\"].isna())\n",
    "    ].index\n",
    "    df = df.drop(indexNames)\n",
    "    \n",
    "    #how many samples in total\n",
    "    t.append(len(df))\n",
    "    \n",
    "    # create a confusion matrix\n",
    "    confusion_matrix = pd.crosstab(\n",
    "        df[\"ACTUAL\"],\n",
    "        df[\"PREDICTION\"],\n",
    "        rownames=[\"ACTUAL\"],\n",
    "        colnames=[\"PREDICTION\"],\n",
    "        margins=True,\n",
    "    )\n",
    "    \n",
    "    #producer's accuracy\n",
    "    confusion_matrix[\"Producer's\"] = [\n",
    "        confusion_matrix.loc[0][0] / confusion_matrix.loc[0][\"All\"] * 100,\n",
    "        confusion_matrix.loc[1][1] / confusion_matrix.loc[1][\"All\"] * 100,\n",
    "        np.nan,\n",
    "    ]\n",
    "    \n",
    "    #user's acc\n",
    "    users_accuracy = pd.Series(\n",
    "        [\n",
    "            confusion_matrix['0'][0] / confusion_matrix['0'][\"All\"] * 100,\n",
    "            confusion_matrix['1'][1] / confusion_matrix['1'][\"All\"] * 100,\n",
    "        ]\n",
    "    ).rename(\"User's\")\n",
    "\n",
    "    confusion_matrix = confusion_matrix.rename({\"0\": 0, \"1\": 1}, axis=1).append(\n",
    "        users_accuracy\n",
    "    )\n",
    "    \n",
    "    #overall acc\n",
    "    confusion_matrix.loc[\"User's\", \"Producer's\"] = (\n",
    "        (confusion_matrix[0][0] + confusion_matrix[1][1])\n",
    "        / confusion_matrix[\"All\"][\"All\"]\n",
    "        * 100\n",
    "    )\n",
    "    df[\"PREDICTION\"] = df[\"PREDICTION\"].astype(str).astype(int)\n",
    "    \n",
    "    #fscore\n",
    "    fscore = pd.Series(\n",
    "        [\n",
    "            (\n",
    "                2\n",
    "                * (\n",
    "                    confusion_matrix.loc[\"User's\"][0]\n",
    "                    * confusion_matrix.loc[0][\"Producer's\"]\n",
    "                )\n",
    "                / (\n",
    "                    confusion_matrix.loc[\"User's\"][0]\n",
    "                    + confusion_matrix.loc[0][\"Producer's\"]\n",
    "                )\n",
    "            )\n",
    "            / 100,\n",
    "            f1_score(df[\"ACTUAL\"], df[\"PREDICTION\"]),\n",
    "        ]\n",
    "    ).rename(\"F-score\")\n",
    "    \n",
    "    #tidy confusion matrix\n",
    "    confusion_matrix = confusion_matrix.append(fscore)\n",
    "    confusion_matrix = confusion_matrix.round(decimals=2)\n",
    "    confusion_matrix = confusion_matrix.rename(\n",
    "        columns={\n",
    "            \"0\": \"NoWater\",\n",
    "            \"1\": \"Water\",\n",
    "            0: \"NoWater\",\n",
    "            1: \"Water\",\n",
    "            \"All\": \"Total\",\n",
    "        },\n",
    "        index={\"0\": \"NoWater\", \"1\": \"Water\", 0: \"NoWater\", 1: \"Water\", \"All\": \"Total\"},\n",
    "    )\n",
    "    print('\\n')\n",
    "    print('n samples for', aez,':', len(df))\n",
    "    print(confusion_matrix)\n",
    "    # saving out the confusion matrix\n",
    "    confusion_matrix.to_csv('../02_Validation_results/WOfS_Assessment/wofs_ls/ConfusionMatrix/'+aez+'_confusion_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples across all regions: 10323\n"
     ]
    }
   ],
   "source": [
    "print('Total number of samples across all regions:', sum(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Last modified:** January 2020\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DE Africa User Guide's [Tags Index](https://) (placeholder as this does not exist yet)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**:  :index:`WOfS`, :index:`fractional cover`, :index:`deafrica_plotting`, :index:`deafrica_datahandling`, :index:`display_map`, :index:`wofs_fuser`, :index:`WOFL`, :index:`masking`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "9e3fa49adf8c4170abfcd954c2ec045a": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     },
     "dc642f11c1fb492ca419b0ed6fc4f8c3": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
