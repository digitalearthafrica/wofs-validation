{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Assessment of Water Observations from Space (WOfS) Product in Africa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaned validation samples from the previous step `02b_Convert_Institution_to_AEZ.ipynb` are ingested here to create confusion mattrices for each agro-ecological zone, and one for the entire continent.\n",
    "\n",
    "\n",
    "**Input data** : `<AEZ>_wofs_ls_validation_points.csv>`\n",
    "\n",
    "**Output_data** : `<AEZ>_confusion_matrix.csv`\n",
    "\n",
    "Last modified: 03/02/2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import rasterio\n",
    "import xarray\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy, scipy.ndimage\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #this will suppress the warnings for multiple UTM zones in your AOI \n",
    "\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score  \n",
    "from deafrica_tools.plotting import map_shapefile,display_map, rgb\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.datahandling import wofs_fuser, mostcommon_crs,load_ard,deepcopy\n",
    "from deafrica_tools.dask import create_local_dask_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets\n",
    "Ground truth points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../02_Validation_results/WOfS_Assessment/wofs_ls/Northern_wofs_ls_validation_points.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Central_wofs_ls_validation_points.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Sahel_wofs_ls_validation_points.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Western_wofs_ls_validation_points.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Indian_ocean_wofs_ls_validation_points.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Southern_wofs_ls_validation_points.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Eastern_wofs_ls_validation_points.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the ground truth data \n",
    "#For each AEZ\n",
    "file_path = ('../02_Validation_results/WOfS_Assessment/wofs_ls/')\n",
    "validation_files = [i for i in glob.glob(os.path.join(file_path, '*.{}'.format('csv')))]\n",
    "validation_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a continental validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "continental = pd.concat([pd.read_csv(f) for f in validation_files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for creating confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(df, aez):\n",
    "\n",
    "    # create a confusion matrix\n",
    "    confusion_matrix = pd.crosstab(\n",
    "        df[\"ACTUAL\"],\n",
    "        df[\"PREDICTION\"],\n",
    "        rownames=[\"ACTUAL\"],\n",
    "        colnames=[\"PREDICTION\"],\n",
    "        margins=True,\n",
    "    )\n",
    "    \n",
    "    #producer's accuracy\n",
    "    confusion_matrix[\"Producer's\"] = [\n",
    "        confusion_matrix.loc[0][0] / confusion_matrix.loc[0][\"All\"] * 100,\n",
    "        confusion_matrix.loc[1][1] / confusion_matrix.loc[1][\"All\"] * 100,\n",
    "        np.nan,\n",
    "    ]\n",
    "    \n",
    "    #user's acc\n",
    "    users_accuracy = pd.Series(\n",
    "        [\n",
    "            confusion_matrix[0][0] / confusion_matrix[0][\"All\"] * 100,\n",
    "            confusion_matrix[1][1] / confusion_matrix[1][\"All\"] * 100,\n",
    "        ]\n",
    "    ).rename(\"User's\")\n",
    "\n",
    "    confusion_matrix = confusion_matrix.append( \n",
    "        users_accuracy\n",
    "    )\n",
    "    \n",
    "    #overall acc\n",
    "    confusion_matrix.loc[\"User's\", \"Producer's\"] = (\n",
    "        (confusion_matrix[0][0] + confusion_matrix[1][1])\n",
    "        / confusion_matrix[\"All\"][\"All\"]\n",
    "        * 100\n",
    "    )\n",
    "    df[\"PREDICTION\"] = df[\"PREDICTION\"].astype(str).astype(int)\n",
    "    \n",
    "    #fscore\n",
    "    fscore = pd.Series(\n",
    "        [\n",
    "            (\n",
    "                2\n",
    "                * (\n",
    "                    confusion_matrix.loc[\"User's\"][0]\n",
    "                    * confusion_matrix.loc[0][\"Producer's\"]\n",
    "                )\n",
    "                / (\n",
    "                    confusion_matrix.loc[\"User's\"][0]\n",
    "                    + confusion_matrix.loc[0][\"Producer's\"]\n",
    "                )\n",
    "            )\n",
    "            / 100,\n",
    "            f1_score(df[\"ACTUAL\"], df[\"PREDICTION\"]),\n",
    "        ]\n",
    "    ).rename(\"F-score\")\n",
    "    \n",
    "    #tidy confusion matrix\n",
    "    confusion_matrix = confusion_matrix.append(fscore)\n",
    "    confusion_matrix = confusion_matrix.round(decimals=2)\n",
    "    confusion_matrix = confusion_matrix.rename(\n",
    "        columns={\n",
    "            \"0\": \"NoWater\",\n",
    "            \"1\": \"Water\",\n",
    "            0: \"NoWater\",\n",
    "            1: \"Water\",\n",
    "            \"All\": \"Total\",\n",
    "        },\n",
    "        index={\"0\": \"NoWater\", \"1\": \"Water\", 0: \"NoWater\", 1: \"Water\", \"All\": \"Total\"},\n",
    "    )\n",
    "    \n",
    "    #remove the nonsensical values in the table\n",
    "    confusion_matrix.loc[\"User's\", 'Total'] = '--'\n",
    "    confusion_matrix.loc['Total', \"Producer's\"] = '--'\n",
    "    confusion_matrix.loc[\"F-score\", 'Total'] = '--'\n",
    "    confusion_matrix.loc[\"F-score\", \"Producer's\"] = '--'\n",
    "    \n",
    "    print('\\n')\n",
    "    print('n samples for', aez,':', len(df))\n",
    "    print(confusion_matrix)\n",
    "    # saving out the confusion matrix\n",
    "    confusion_matrix.to_csv('../02_Validation_results/WOfS_Assessment/wofs_ls/ConfusionMatrix/'+aez+'_confusion_matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AEZ confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "n samples for Northern : 1125\n",
      "         NoWater   Water   Total Producer's\n",
      "ACTUAL                                     \n",
      "NoWater   393.00   71.00   464.0       84.7\n",
      "Water     113.00  548.00   661.0       82.9\n",
      "Total     506.00  619.00  1125.0         --\n",
      "User's     77.67   88.53      --      83.64\n",
      "F-score     0.81    0.86      --         --\n",
      "\n",
      "\n",
      "n samples for Central : 606\n",
      "         NoWater   Water  Total Producer's\n",
      "ACTUAL                                    \n",
      "NoWater    59.00   15.00   74.0      79.73\n",
      "Water     113.00  419.00  532.0      78.76\n",
      "Total     172.00  434.00  606.0         --\n",
      "User's     34.30   96.54     --      78.88\n",
      "F-score     0.48    0.87     --         --\n",
      "\n",
      "\n",
      "n samples for Sahel : 1224\n",
      "         NoWater   Water   Total Producer's\n",
      "ACTUAL                                     \n",
      "NoWater   390.00  120.00   510.0      76.47\n",
      "Water      80.00  634.00   714.0       88.8\n",
      "Total     470.00  754.00  1224.0         --\n",
      "User's     82.98   84.08      --      83.66\n",
      "F-score     0.80    0.86      --         --\n",
      "\n",
      "\n",
      "n samples for Western : 1055\n",
      "         NoWater   Water   Total Producer's\n",
      "ACTUAL                                     \n",
      "NoWater   160.00   19.00   179.0      89.39\n",
      "Water     197.00  679.00   876.0      77.51\n",
      "Total     357.00  698.00  1055.0         --\n",
      "User's     44.82   97.28      --      79.53\n",
      "F-score     0.60    0.86      --         --\n",
      "\n",
      "\n",
      "n samples for Indian_ocean : 2283\n",
      "         NoWater    Water   Total Producer's\n",
      "ACTUAL                                      \n",
      "NoWater   376.00    49.00   425.0      88.47\n",
      "Water     491.00  1367.00  1858.0      73.57\n",
      "Total     867.00  1416.00  2283.0         --\n",
      "User's     43.37    96.54      --      76.35\n",
      "F-score     0.58     0.84      --         --\n",
      "\n",
      "\n",
      "n samples for Southern : 2155\n",
      "         NoWater    Water   Total Producer's\n",
      "ACTUAL                                      \n",
      "NoWater   684.00    40.00   724.0      94.48\n",
      "Water     345.00  1086.00  1431.0      75.89\n",
      "Total    1029.00  1126.00  2155.0         --\n",
      "User's     66.47    96.45      --      82.13\n",
      "F-score     0.78     0.85      --         --\n",
      "\n",
      "\n",
      "n samples for Eastern : 2669\n",
      "         NoWater    Water   Total Producer's\n",
      "ACTUAL                                      \n",
      "NoWater   651.00    63.00   714.0      91.18\n",
      "Water     277.00  1678.00  1955.0      85.83\n",
      "Total     928.00  1741.00  2669.0         --\n",
      "User's     70.15    96.38      --      87.26\n",
      "F-score     0.79     0.91      --         --\n"
     ]
    }
   ],
   "source": [
    "for v in validation_files:\n",
    "    df = pd.read_csv(v, delimiter=\",\")\n",
    "    aez = v[49:-30]\n",
    "    create_confusion_matrix(df, aez)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continental confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "n samples for Continental : 11117\n",
      "         NoWater    Water    Total Producer's\n",
      "ACTUAL                                       \n",
      "NoWater  2713.00   377.00   3090.0       87.8\n",
      "Water    1616.00  6411.00   8027.0      79.87\n",
      "Total    4329.00  6788.00  11117.0         --\n",
      "User's     62.67    94.45       --      82.07\n",
      "F-score     0.73     0.87       --         --\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([pd.read_csv(f) for f in validation_files])\n",
    "\n",
    "create_confusion_matrix(df, 'Continental')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Last modified:** January 2020\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "9e3fa49adf8c4170abfcd954c2ec045a": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     },
     "dc642f11c1fb492ca419b0ed6fc4f8c3": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
