{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Assessment of Water Observations from Space (WOfS) Product in Africa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaned validation samples from the previous step `02b_Convert_Institution_to_AEZ.ipynb` are ingested here to create confusion mattrices for each agro-ecological zone, and one for the entire continent.\n",
    "\n",
    "\n",
    "**Input data** : `<AEZ>_wofs_ls_validation_points.csv>`\n",
    "\n",
    "**Output_data** : `<AEZ>_confusion_matrix.csv`\n",
    "\n",
    "Last modified: 04/02/2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets\n",
    "Ground truth points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../02_Validation_results/WOfS_Assessment/wofs_ls/Northern_wofs_ls_validation_points.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Central_wofs_ls_validation_points.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Sahel_wofs_ls_validation_points.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Western_wofs_ls_validation_points.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Indian_ocean_wofs_ls_validation_points.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Southern_wofs_ls_validation_points.csv',\n",
       " '../02_Validation_results/WOfS_Assessment/wofs_ls/Eastern_wofs_ls_validation_points.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the ground truth data \n",
    "#For each AEZ\n",
    "file_path = ('../02_Validation_results/WOfS_Assessment/wofs_ls/')\n",
    "validation_files = [i for i in glob.glob(os.path.join(file_path, '*.{}'.format('csv')))]\n",
    "validation_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a continental validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "continental = pd.concat([pd.read_csv(f) for f in validation_files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for creating confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(df, aez):\n",
    "\n",
    "    # create a confusion matrix\n",
    "    confusion_matrix = pd.crosstab(\n",
    "        df[\"ACTUAL\"],\n",
    "        df[\"PREDICTION\"],\n",
    "        rownames=[\"ACTUAL\"],\n",
    "        colnames=[\"PREDICTION\"],\n",
    "        margins=True,\n",
    "    )\n",
    "    \n",
    "    #producer's accuracy\n",
    "    confusion_matrix[\"Producer's\"] = [\n",
    "        confusion_matrix.loc[0][0] / confusion_matrix.loc[0][\"All\"] * 100,\n",
    "        confusion_matrix.loc[1][1] / confusion_matrix.loc[1][\"All\"] * 100,\n",
    "        np.nan,\n",
    "    ]\n",
    "    \n",
    "    #user's acc\n",
    "    users_accuracy = pd.Series(\n",
    "        [\n",
    "            confusion_matrix[0][0] / confusion_matrix[0][\"All\"] * 100,\n",
    "            confusion_matrix[1][1] / confusion_matrix[1][\"All\"] * 100,\n",
    "        ]\n",
    "    ).rename(\"User's\")\n",
    "\n",
    "    confusion_matrix = confusion_matrix.append( \n",
    "        users_accuracy\n",
    "    )\n",
    "    \n",
    "    #overall acc\n",
    "    confusion_matrix.loc[\"User's\", \"Producer's\"] = (\n",
    "        (confusion_matrix[0][0] + confusion_matrix[1][1])\n",
    "        / confusion_matrix[\"All\"][\"All\"]\n",
    "        * 100\n",
    "    )\n",
    "    df[\"PREDICTION\"] = df[\"PREDICTION\"].astype(str).astype(int)\n",
    "    \n",
    "    #fscore\n",
    "    fscore = pd.Series(\n",
    "        [\n",
    "            (\n",
    "                2\n",
    "                * (\n",
    "                    confusion_matrix.loc[\"User's\"][0]\n",
    "                    * confusion_matrix.loc[0][\"Producer's\"]\n",
    "                )\n",
    "                / (\n",
    "                    confusion_matrix.loc[\"User's\"][0]\n",
    "                    + confusion_matrix.loc[0][\"Producer's\"]\n",
    "                )\n",
    "            )\n",
    "            / 100,\n",
    "            f1_score(df[\"ACTUAL\"], df[\"PREDICTION\"]),\n",
    "        ]\n",
    "    ).rename(\"F-score\")\n",
    "    \n",
    "    #tidy confusion matrix\n",
    "    confusion_matrix = confusion_matrix.append(fscore)\n",
    "    confusion_matrix = confusion_matrix.round(decimals=2)\n",
    "    confusion_matrix = confusion_matrix.rename(\n",
    "        columns={\n",
    "            \"0\": \"NoWater\",\n",
    "            \"1\": \"Water\",\n",
    "            0: \"NoWater\",\n",
    "            1: \"Water\",\n",
    "            \"All\": \"Total\",\n",
    "        },\n",
    "        index={\"0\": \"NoWater\", \"1\": \"Water\", 0: \"NoWater\", 1: \"Water\", \"All\": \"Total\"},\n",
    "    )\n",
    "    \n",
    "    #remove the nonsensical values in the table\n",
    "    confusion_matrix.loc[\"User's\", 'Total'] = '--'\n",
    "    confusion_matrix.loc['Total', \"Producer's\"] = '--'\n",
    "    confusion_matrix.loc[\"F-score\", 'Total'] = '--'\n",
    "    confusion_matrix.loc[\"F-score\", \"Producer's\"] = '--'\n",
    "    \n",
    "    print('\\n')\n",
    "    print('n samples for', aez,':', len(df))\n",
    "    print(confusion_matrix)\n",
    "    # saving out the confusion matrix\n",
    "    confusion_matrix.to_csv('../02_Validation_results/WOfS_Assessment/wofs_ls/ConfusionMatrix/'+aez+'_confusion_matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AEZ confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "n samples for Northern : 1180\n",
      "         NoWater   Water   Total Producer's\n",
      "ACTUAL                                     \n",
      "NoWater   387.00   63.00   450.0       86.0\n",
      "Water     109.00  621.00   730.0      85.07\n",
      "Total     496.00  684.00  1180.0         --\n",
      "User's     78.02   90.79      --      85.42\n",
      "F-score     0.82    0.88      --         --\n",
      "\n",
      "\n",
      "n samples for Central : 590\n",
      "         NoWater   Water  Total Producer's\n",
      "ACTUAL                                    \n",
      "NoWater    66.00   13.00   79.0      83.54\n",
      "Water     108.00  403.00  511.0      78.86\n",
      "Total     174.00  416.00  590.0         --\n",
      "User's     37.93   96.88     --      79.49\n",
      "F-score     0.52    0.87     --         --\n",
      "\n",
      "\n",
      "n samples for Sahel : 1236\n",
      "         NoWater   Water   Total Producer's\n",
      "ACTUAL                                     \n",
      "NoWater   409.00  119.00   528.0      77.46\n",
      "Water      85.00  623.00   708.0      87.99\n",
      "Total     494.00  742.00  1236.0         --\n",
      "User's     82.79   83.96      --       83.5\n",
      "F-score     0.80    0.86      --         --\n",
      "\n",
      "\n",
      "n samples for Western : 1107\n",
      "         NoWater   Water   Total Producer's\n",
      "ACTUAL                                     \n",
      "NoWater   169.00   18.00   187.0      90.37\n",
      "Water     235.00  685.00   920.0      74.46\n",
      "Total     404.00  703.00  1107.0         --\n",
      "User's     41.83   97.44      --      77.15\n",
      "F-score     0.57    0.84      --         --\n",
      "\n",
      "\n",
      "n samples for Indian_ocean : 2082\n",
      "         NoWater    Water   Total Producer's\n",
      "ACTUAL                                      \n",
      "NoWater   333.00    45.00   378.0       88.1\n",
      "Water     455.00  1249.00  1704.0       73.3\n",
      "Total     788.00  1294.00  2082.0         --\n",
      "User's     42.26    96.52      --      75.98\n",
      "F-score     0.57     0.83      --         --\n",
      "\n",
      "\n",
      "n samples for Southern : 2076\n",
      "         NoWater    Water   Total Producer's\n",
      "ACTUAL                                      \n",
      "NoWater   659.00    37.00   696.0      94.68\n",
      "Water     344.00  1036.00  1380.0      75.07\n",
      "Total    1003.00  1073.00  2076.0         --\n",
      "User's     65.70    96.55      --      81.65\n",
      "F-score     0.78     0.84      --         --\n",
      "\n",
      "\n",
      "n samples for Eastern : 2574\n",
      "         NoWater    Water   Total Producer's\n",
      "ACTUAL                                      \n",
      "NoWater   650.00    61.00   711.0      91.42\n",
      "Water     266.00  1597.00  1863.0      85.72\n",
      "Total     916.00  1658.00  2574.0         --\n",
      "User's     70.96    96.32      --       87.3\n",
      "F-score     0.80     0.91      --         --\n"
     ]
    }
   ],
   "source": [
    "for v in validation_files:\n",
    "    df = pd.read_csv(v, delimiter=\",\")\n",
    "    aez = v[49:-30]\n",
    "    create_confusion_matrix(df, aez)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continental confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "n samples for Continental : 10845\n",
      "         NoWater    Water    Total Producer's\n",
      "ACTUAL                                       \n",
      "NoWater  2673.00   356.00   3029.0      88.25\n",
      "Water    1602.00  6214.00   7816.0       79.5\n",
      "Total    4275.00  6570.00  10845.0         --\n",
      "User's     62.53    94.58       --      81.95\n",
      "F-score     0.73     0.86       --         --\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([pd.read_csv(f) for f in validation_files])\n",
    "\n",
    "create_confusion_matrix(df, 'Continental')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Last modified:** January 2020\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "9e3fa49adf8c4170abfcd954c2ec045a": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     },
     "dc642f11c1fb492ca419b0ed6fc4f8c3": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
