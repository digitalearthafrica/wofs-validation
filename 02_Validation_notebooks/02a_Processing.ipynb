{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point-based and Parallel Processing Water Observations from Space (WOfS) Product in Africa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description \n",
    "The [Water Observations from Space (WOfS)](https://www.ga.gov.au/scientific-topics/community-safety/flood/wofs/about-wofs) is a derived product from Landsat 8 satellite observations as part of provisional Landsat 8 Collection 2 surface reflectance and shows surface water detected in Africa.\n",
    "Individual water classified images are called Water Observation Feature Layers (WOFLs), and are created in a 1-to-1 relationship with the input satellite data. \n",
    "Hence there is one WOFL for each satellite dataset processed for the occurrence of water.\n",
    "\n",
    "The data in a WOFL is stored as a bit field. This is a binary number, where each digit of the number is independantly set or not based on the presence (1) or absence (0) of a particular attribute (water, cloud, cloud shadow etc). In this way, the single decimal value associated to each pixel can provide information on a variety of features of that pixel. \n",
    "For more information on the structure of WOFLs and how to interact with them, see [Water Observations from Space](../Datasets/Water_Observations_from_Space.ipynb) and [Applying WOfS bitmasking](../Frequently_used_code/Applying_WOfS_bitmasking.ipynb) notebooks.\n",
    "\n",
    "This notebook explains how you can query WOfS product for each collected validation points in Africa based on point-based sampling approach. \n",
    "\n",
    "The notebook demonstrates how to:\n",
    "\n",
    "1. Load validation points for each partner institutions\n",
    "2. Query WOFL data for validation points and capture available WOfS defined class using point-based sampling and multiprocessing functionality\n",
    "3. Extract a LUT for each point that contains both information for validation points and WOfS class as well number of clear observation in each month \n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input data** : `<INSTITUTION>_ValidationPoints.csv>`\n",
    "\n",
    "**Output_data** : `<INSTITUTION>_wofs_ls_valid.csv`\n",
    "\n",
    "Last modified: 04/02/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datacube\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "from datacube.utils import masking, geometry \n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.datahandling import wofs_fuser, deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions = ['OSS', 'RCMRD', 'AGRHYMET', 'AFRIGIST']\n",
    "ncpus = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open data, convert to geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSS (8673, 19)\n",
      "RCMRD (8899, 17)\n",
      "AGRHYMET (8724, 18)\n",
      "AFRIGIST (13835, 19)\n"
     ]
    }
   ],
   "source": [
    "gdfs = []\n",
    "for i in institutions:\n",
    "    path2csv = (\n",
    "        \"../02_Validation_data/Processed/\" + i + \"/\" + i + \"_ValidationPoints.csv\"\n",
    "    )\n",
    "    df = pd.read_csv(path2csv, delimiter=\",\")\n",
    "\n",
    "    geometries = [Point(xy) for xy in zip(df.LON, df.LAT)]\n",
    "    gdf = GeoDataFrame(df, crs=\"epsg:4326\", geometry=geometries)\n",
    "\n",
    "    gdf.to_file(\n",
    "        filename=\"../02_Validation_data/Processed/\"\n",
    "        +i+\"/\"+i+\"_ValidationPoints.geojson\"\n",
    "    )\n",
    "\n",
    "    # converting CRS to metric\n",
    "    gdf = gdf.to_crs(\"epsg:6933\")\n",
    "\n",
    "    # Checking the size of the input data\n",
    "    print(i, gdf.shape)\n",
    "\n",
    "    gdfs.append(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample WOfS at the ground truth coordinates\n",
    "\n",
    "**Assumptions for ODC data query:**\n",
    "- WOfS data is loaded for the nearest pixel to the validation sample lat/lon\n",
    "- WOfS Data is loaded in a 10 day window around the beginning of each month\n",
    "- IF WOfS has a 'wet' and 'clear' value anytime during the 10 day window then the pixel is said to be 'wet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate query object \n",
    "query ={'group_by':'solar_day',\n",
    "        'resampling':'nearest'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions to query WOfS database\n",
    "\n",
    "- according to the first five days before and after of each calendar month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wofs_for_point(index, row, input_data, query, results_wet, results_clear):\n",
    "    dc = datacube.Datacube(app=\"WOfS_accuracy\")\n",
    "\n",
    "    # get the month value for each index\n",
    "    month = input_data.loc[index][\"MONTH\"]\n",
    "\n",
    "    # get the value for time including year, month, start date and end date\n",
    "    timeYM = \"2018-\" + f\"{month:02d}\"\n",
    "    start_date = np.datetime64(timeYM) - np.timedelta64(5, \"D\")\n",
    "    end_date = np.datetime64(timeYM) + np.timedelta64(5, \"D\")\n",
    "    time = (str(start_date), str(end_date))\n",
    "    plot_id = input_data.loc[index][\"PLOT_ID\"]\n",
    "\n",
    "    # having the original query as it is\n",
    "    dc_query = deepcopy(query)\n",
    "    geom = geometry.Geometry(\n",
    "        input_data.geometry.values[index].__geo_interface__, geometry.CRS(\"EPSG:6933\")\n",
    "    )\n",
    "    q = {\"geopolygon\": geom}\n",
    "    t = {\"time\": time}\n",
    "\n",
    "    # updating the query\n",
    "    dc_query.update(t)\n",
    "    dc_query.update(q)\n",
    "\n",
    "    # loading landsat-8 WOfs product and set the values\n",
    "    # for x and y (point-based) and also (window-based)\n",
    "    wofls = dc.load(\n",
    "        product=\"wofs_ls\",\n",
    "        skip_broken_datasets=True,\n",
    "        y=(input_data.geometry.y[index], input_data.geometry.y[index]),\n",
    "        x=(input_data.geometry.x[index], input_data.geometry.x[index]),\n",
    "        crs=\"EPSG:6933\",\n",
    "        time=time,\n",
    "        output_crs=\"EPSG:6933\",\n",
    "        resolution=(-30, 30),\n",
    "    )\n",
    "\n",
    "    # exclude the records that wofl return as empty for water\n",
    "    if not \"water\" in wofls:\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        # Define a mask for wet and clear pixels\n",
    "        wet_nocloud = {\"wet\": True}\n",
    "        # Define a mask for dry and clear pixels\n",
    "        dry_nocloud = {\"dry\": True}\n",
    "        wofl_wetnocloud = masking.make_mask(wofls, **wet_nocloud).astype(int)\n",
    "        wofl_drynocloud = masking.make_mask(wofls, **dry_nocloud).astype(int)\n",
    "        clear = (wofl_wetnocloud | wofl_drynocloud).water.all(dim=[\"x\", \"y\"]).values\n",
    "        # record the total number of clear observations for each point in each month\n",
    "        # and use it to filter out month with no valid data\n",
    "        n_clear = clear.sum()\n",
    "        # condition to identify whether WOfS seen water in specific month for a particular location\n",
    "        if n_clear > 0:\n",
    "            wet = wofl_wetnocloud.isel(time=clear).water.max().values\n",
    "        else:\n",
    "            wet = 0\n",
    "        # updating results for both wet and clear observations\n",
    "        results_wet.update({str(int(plot_id)) + \"_\" + str(month): int(wet)})\n",
    "        results_clear.update({str(int(plot_id)) + \"_\" + str(month): int(n_clear)})\n",
    "\n",
    "        return time\n",
    "\n",
    "\n",
    "# parallel function for above function\n",
    "def _parallel_fun(input_data, query, ncpus):\n",
    "\n",
    "    manager = mp.Manager()\n",
    "    results_wet = manager.dict()\n",
    "    results_clear = manager.dict()\n",
    "\n",
    "    # progress bar\n",
    "    pbar = tqdm(total=len(input_data))\n",
    "\n",
    "    def update(*a):\n",
    "        pbar.update()\n",
    "\n",
    "    with mp.Pool(ncpus) as pool:\n",
    "        for index, row in input_data.iterrows():\n",
    "            pool.apply_async(\n",
    "                get_wofs_for_point,\n",
    "                [index, row, input_data, query, results_wet, results_clear],\n",
    "                callback=update,\n",
    "            )\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        pbar.close()\n",
    "\n",
    "    return results_wet, results_clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through dataframes and extract wofs data in parallel\n",
    "\n",
    "Results are saved as .csv in the `../02_Validation_results/WOfS_Assessment/wofs_ls/Institutions/` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell directly below is for testing purposes only (hard to debug a parallel workflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_wet_test = dict()\n",
    "# results_clear_test = dict()\n",
    "\n",
    "# for index, row in gdfs[0][0:14].iterrows():\n",
    "#     time = get_wofs_for_point(index, row, input_data, query, results_wet_test, results_clear_test)\n",
    "# #     print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running OSS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8673/8673 [03:01<00:00, 47.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of NaNs 44\n",
      "Running RCMRD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8899/8899 [02:57<00:00, 50.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of NaNs 214\n",
      "Running AGRHYMET\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8724/8724 [03:07<00:00, 46.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of NaNs 216\n",
      "Running AFRIGIST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 13832/13835 [05:37<00:00, 41.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of NaNs 307\n"
     ]
    }
   ],
   "source": [
    "for input_data, i in zip(gdfs, institutions):\n",
    "    print(\"Running\", i)\n",
    "\n",
    "    # run the parallel function\n",
    "    wet, clear = _parallel_fun(input_data, query, ncpus=ncpus)\n",
    "\n",
    "    # extracting the final table with both CEO labels\n",
    "    # and WOfS class Wet and clear observations\n",
    "    wetdf = pd.DataFrame.from_dict(wet, orient=\"index\")\n",
    "    cleardf = pd.DataFrame.from_dict(clear, orient=\"index\")\n",
    "    df2 = wetdf.merge(cleardf, left_index=True, right_index=True)\n",
    "    df2 = df2.rename(columns={\"0_x\": \"CLASS_WET\", \"0_y\": \"CLEAR_OBS\"})\n",
    "\n",
    "    # split the index (which is plotid + month) into seperate columns\n",
    "    for index, row in df2.iterrows():\n",
    "        df2.at[index, \"PLOT_ID\"] = index.split(\"_\")[0] + \".0\"\n",
    "        df2.at[index, \"MONTH\"] = index.split(\"_\")[1]\n",
    "\n",
    "    # reset the index\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "\n",
    "    # convert plot id and month to str to help with matching\n",
    "    input_data[\"PLOT_ID\"] = input_data.PLOT_ID.astype(str)\n",
    "    input_data[\"MONTH\"] = input_data.MONTH.astype(str)\n",
    "\n",
    "    # merge both dataframe at locations where plotid and month match\n",
    "    final_df = pd.merge(input_data, df2, on=[\"PLOT_ID\", \"MONTH\"], how=\"outer\")\n",
    "    \n",
    "    # only keep columns we need\n",
    "    final_df = final_df[\n",
    "        [\n",
    "            \"PLOT_ID\",\n",
    "            \"LON\",\n",
    "            \"LAT\",\n",
    "            \"MONTH\",\n",
    "            \"WATERFLAG\",\n",
    "            \"CLASS_WET\",\n",
    "            \"CLEAR_OBS\",\n",
    "            \"geometry\"\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # check number of nan rows\n",
    "    nans = final_df[\"CLASS_WET\"].isna().sum()\n",
    "    print(\"No of NaNs\", nans)\n",
    "\n",
    "    # export results\n",
    "    final_df.to_csv(\n",
    "        (\n",
    "            \"../02_Validation_results/WOfS_Assessment/wofs_ls/Institutions/\"\n",
    "            + i\n",
    "            + \"_wofs_ls_valid_test.csv\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Last modified:** September 2020\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.6\n"
     ]
    }
   ],
   "source": [
    "print(datacube.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "9e3fa49adf8c4170abfcd954c2ec045a": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     },
     "dc642f11c1fb492ca419b0ed6fc4f8c3": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
