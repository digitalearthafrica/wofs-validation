{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Institution data to AEZs\n",
    "\n",
    "The processing steps are run on the data as it comes from the institutions, but now we can take that and turn it into AEZ regions to test how well our method does based on regional differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plan is to read in the institution data as gpd tables, combine them into one big table and then make cuts to that big table based on the shape files of the AEZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the institution files, preferably the ones that have had columns dropped already in the processing step\n",
    "AGRYHMET = pd.read_csv('../02_Validation_results/WOfS_Assessment/wofs_ls/Institutions/AGRYHMET_wofs_ls_valid.csv')\n",
    "RCMRD = pd.read_csv('../02_Validation_results/WOfS_Assessment/wofs_ls/Institutions/RCMRD_wofs_ls_valid.csv')\n",
    "OSS = pd.read_csv('../02_Validation_results/WOfS_Assessment/wofs_ls/Institutions/OSS_wofs_ls_valid.csv')\n",
    "AFRIGIST = pd.read_csv('../02_Validation_results/WOfS_Assessment/wofs_ls/Institutions/AFRIGIST_good_wofs_ls_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of points: 36619\n"
     ]
    }
   ],
   "source": [
    "# concatenate the institution data into a big table and check total length\n",
    "combined = pd.concat([AGRYHMET, RCMRD, OSS, AFRIGIST]).reset_index(drop=True).drop('Unnamed: 0', axis=1)\n",
    "print('Total Number of points:', len(combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the combined table as a csv\n",
    "combined.to_csv('../02_Validation_results/WOfS_Assessment/wofs_ls/Institutions/Africa_Combined_wofs_ls_valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that they are all combined into one table, we need to turn it into geopandas to be able to compare it with the shape files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a geopandas object\n",
    "geo_combined = gpd.GeoDataFrame(combined, geometry=gpd.points_from_xy(combined.LON, combined.LAT), crs='EPSG:4326')\n",
    "\n",
    "# save as a geojson file for later\n",
    "geo_combined.to_file('../02_Validation_results/WOfS_Assessment/wofs_ls/Institutions/Africa_Combined_wofs_ls_valid.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip points to AEZ's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "east = gpd.read_file('../02_Validation_data/AEZ_shapefiles/Eastern.shp')\n",
    "west = gpd.read_file('../02_Validation_data/AEZ_shapefiles/Western.shp')\n",
    "north = gpd.read_file('../02_Validation_data/AEZ_shapefiles/Northern.shp')\n",
    "south = gpd.read_file('../02_Validation_data/AEZ_shapefiles/Southern.shp')\n",
    "sahel = gpd.read_file('../02_Validation_data/AEZ_shapefiles/Sahel.shp')\n",
    "central = gpd.read_file('../02_Validation_data/AEZ_shapefiles/Central.shp')\n",
    "io = gpd.read_file('../02_Validation_data/AEZ_shapefiles/Indian_ocean.shp')\n",
    "\n",
    "shapes = [east,west,north,south,sahel,central,io]\n",
    "aezs= ['Eastern', 'Western', 'Northern', 'Southern', 'Sahel', 'Central', 'Indian_ocean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through AEZs and clip points to region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eastern 6093\n",
      "Western 8038\n",
      "Northern 3597\n",
      "Southern 4435\n",
      "Sahel 3577\n",
      "Central 7206\n",
      "Indian_ocean 3673\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "total=[]\n",
    "for s, a in zip(shapes, aezs):\n",
    "    gdf = gpd.overlay(geo_combined, s, how='intersection')\n",
    "    print(a, len(gdf))\n",
    "    total.append(len(gdf))\n",
    "    # save out to file for the accuracy assesments\n",
    "    gdf.to_csv('../02_Validation_results/WOfS_Assessment/wofs_ls/'+a+'_wofs_ls_valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the sum of the points matches the number of points in the initial dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum(total))\n",
    "sum(total)== len(geo_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
